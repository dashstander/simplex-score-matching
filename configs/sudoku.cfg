[data]
seq_len = 81
vocab_size = 9
batch_size = 2048
epochs = 100
num_val_batches = 1
num_train_batches = 100000
data_path = "/home/dashiell/sudoku.npz"



[model]
vocab_size = ${data.vocab_size}
max_length = ${data.seq_len}
num_layers = 4
num_heads = 8
embed_dim = 128
model_dim = 256
mlp_dim = 128
time_dim = 16
dropout = 0.1
attention_dropout = 0.1

[model.ema]
decay = 0.999
warmup = 1000


[sde]
num_fwd_steps = 100
num_bwd_steps = 1000
beta_0 = 0.1
beta_f = 5.0
cfg_weight = 10.0

[optimizer]
algo = "AdamW"
init_lr = 0.000001
peak_lr = 0.0002
lr = 0.0000001
warmup_steps = 10000
decay_steps = 500000
grad_clip = 2.0